# Transformer Sequence Encoder Configuration
# Transformer-based sequence encoding with self-attention

_target_: tabular_ssl.models.components.TransformerSequenceEncoder

input_dim: 512
hidden_dim: 512
num_layers: 4
num_heads: 8
dim_feedforward: 2048
dropout: 0.1
max_seq_length: 2048 
# Simplified training configuration - all training settings in one file

# PyTorch Lightning Trainer
trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: auto
  devices: auto
  precision: "16-mixed"
  max_epochs: 100
  gradient_clip_val: 1.0
  val_check_interval: 0.25
  log_every_n_steps: 50
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  deterministic: false

# Callbacks (inline for simplicity)
callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: "epoch_{epoch:03d}"
    monitor: "val/loss"
    mode: "min"
    save_top_k: 3
    save_last: true
    auto_insert_metric_name: false

  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val/loss"
    mode: "min"
    patience: 15
    min_delta: 0.001

  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step" 
# @package _global_

# Large S4 sequence model experiment
# Usage: python train.py experiment=s4_large

defaults:
  - override /model/event_encoder: mlp
  - override /model/sequence_encoder: s4
  - override /model/projection_head: mlp
  - override /model/prediction_head: classification

tags: ["s4", "large", "sequence", "long-range"]

model:
  # Event encoder settings
  event_encoder:
    input_dim: 64
    hidden_dims: [128, 256]
    output_dim: 512
    dropout: 0.1
    
  # S4 sequence encoder settings
  sequence_encoder:
    input_dim: 512
    hidden_dim: 512
    num_layers: 6
    dropout: 0.1
    bidirectional: false
    max_sequence_length: 2048
    
  # Projection head settings
  projection_head:
    input_dim: 512
    hidden_dims: [256, 128]
    output_dim: 64
    
  # Prediction head settings
  prediction_head:
    input_dim: 64
    num_classes: 2
    hidden_dims: [32]
    
  # Training settings
  learning_rate: 1e-4
  weight_decay: 1e-2
  optimizer_type: adamw
  scheduler_type: cosine

trainer:
  max_epochs: 100
  gradient_clip_val: 0.5
  precision: 16-mixed
  accumulate_grad_batches: 2

data:
  batch_size: 32  # Smaller batch for larger model
  sequence_length: 128
  num_workers: 4 
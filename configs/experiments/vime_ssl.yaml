# @package _global_

# VIME Self-Supervised Learning Experiment
# Based on "VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain"
# Usage: python train.py +experiment=vime_ssl

defaults:
  - override /data: credit_card
  - override /model/event_encoder: mlp
  - override /model/sequence_encoder: transformer
  - override /model/projection_head: mlp
  - override /model/corruption: vime

tags: ["vime", "ssl", "mask_estimation", "value_imputation"]

# Model configuration for VIME
model:
  # Event encoder for processing tabular features
  event_encoder:
    input_dim: 64
    hidden_dims: [128, 256, 512]
    output_dim: 512
    dropout: 0.1
    activation: gelu
    use_batch_norm: true
    
  # Sequence encoder (optional for VIME, but useful for sequential data)
  sequence_encoder:
    input_dim: 512
    hidden_dim: 512
    num_layers: 3
    num_heads: 8
    dim_feedforward: 1024
    dropout: 0.1
    
  # Projection head for feature reconstruction
  projection_head:
    input_dim: 512
    hidden_dims: [256, 128]
    output_dim: 64
    dropout: 0.1
    
  # VIME-specific heads
  mask_estimation_head:
    _target_: tabular_ssl.models.components.ClassificationHead
    input_dim: 64
    num_classes: 2  # Binary: masked or not masked
    hidden_dims: [32]
    dropout: 0.1
    
  value_imputation_head:
    _target_: tabular_ssl.models.components.MLPProjectionHead
    input_dim: 64
    hidden_dims: [128, 256]
    output_dim: ${model.event_encoder.input_dim}  # Reconstruct original features
    dropout: 0.1
    
  # Corruption strategy
  corruption:
    corruption_rate: 0.3
    
  # Training parameters
  learning_rate: 1e-4
  weight_decay: 0.01
  optimizer_type: adamw
  scheduler_type: cosine
  
  # VIME loss weights
  mask_estimation_weight: 1.0
  value_imputation_weight: 2.0
  consistency_weight: 0.5

# Data configuration
data:
  sequence_length: 32
  batch_size: 64
  
  # Sample data configuration
  sample_data_config:
    n_users: 1000
    sequence_length: 32

# Training configuration
trainer:
  max_epochs: 100
  gradient_clip_val: 1.0
  precision: 16-mixed
  
  # Validation settings
  val_check_interval: 0.25
  log_every_n_steps: 25
  
  # Enable checkpointing
  enable_checkpointing: true

# Callbacks
callbacks:
  model_checkpoint:
    monitor: "val/total_loss"
    save_top_k: 3
    mode: "min"
  early_stopping:
    monitor: "val/total_loss"
    patience: 15
    min_delta: 0.001

# Logging configuration
logger:
  wandb:
    project: "tabular-ssl-vime"
    tags: ${tags}
    group: "vime_experiments" 